{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [   0    1    2 ... 6469 6472 6475] Test: [  11   12   13 ... 6463 6468 6474]\n",
      "Train Cities: ['Athens']\n",
      "Test Cities: ['Irakleion']\n",
      "\n",
      "Train: [   0    1    2 ... 6472 6474 6475] Test: [  23   24   25 ... 6467 6470 6477]\n",
      "Train Cities: ['Athens' 'Irakleion']\n",
      "Test Cities: ['Patra']\n",
      "\n",
      "Train: [   0    1    2 ... 6474 6475 6477] Test: [  36   37   38 ... 6465 6478 6479]\n",
      "Train Cities: ['Athens' 'Irakleion' 'Patra']\n",
      "Test Cities: ['Thessaloniki']\n",
      "\n",
      "Train: [   0    1    2 ... 6477 6478 6479] Test: [  57   58   59 ... 6471 6473 6476]\n",
      "Train Cities: ['Athens' 'Irakleion' 'Patra' 'Thessaloniki']\n",
      "Test Cities: ['Larisa']\n",
      "\n",
      "Train: [   0    1    2 ... 6477 6478 6479] Test: [6480 6481 6482 ... 7557 7558 7559]\n",
      "Train Cities: ['Athens' 'Irakleion' 'Patra' 'Thessaloniki' 'Larisa']\n",
      "Test Cities: [nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "\n",
    "class GroupedTimeSeriesSplit(_BaseKFold):\n",
    "    def __init__(self, n_splits=5, group_column=None):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.n_splits = n_splits\n",
    "        self.group_column = group_column\n",
    "\n",
    "    def split(self, data, date_column=None):\n",
    "        if self.group_column is None:\n",
    "            raise ValueError(\"Group column not specified.\")\n",
    "\n",
    "        unique_groups = data[self.group_column].unique()\n",
    "        n_groups = len(unique_groups)\n",
    "\n",
    "        if n_groups < self.n_splits:\n",
    "            raise ValueError(\"Number of groups is less than n_splits.\")\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=self.n_splits)\n",
    "\n",
    "        for train_index, test_index in tscv.split(unique_groups):\n",
    "            train_groups = unique_groups[train_index]\n",
    "            test_groups = unique_groups[test_index]\n",
    "            train_mask = data[self.group_column].isin(train_groups)\n",
    "            test_mask = data[self.group_column].isin(test_groups)\n",
    "            yield np.where(train_mask)[0], np.where(test_mask)[0]\n",
    "\n",
    "# Sample data\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Desktop\\\\studies\\\\SIT\\\\placement\\\\iqgate\\\\dataset\\\\train.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouped Time Series Cross-Validation\n",
    "# Grouped Time Series Cross-Validation\n",
    "gkf = GroupedTimeSeriesSplit(n_splits=min(5, len(df)), group_column=\"city\")\n",
    "\n",
    "for train_index, test_index in gkf.split(df):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    print(\"Train Cities:\", df.iloc[train_index][\"city\"].unique())\n",
    "    print(\"Test Cities:\", df.iloc[test_index][\"city\"].unique())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       500ml\n",
      "1       1.5lt\n",
      "2       330ml\n",
      "3       500ml\n",
      "4       330ml\n",
      "        ...  \n",
      "7555      NaN\n",
      "7556      NaN\n",
      "7557      NaN\n",
      "7558      NaN\n",
      "7559      NaN\n",
      "Name: capacity, Length: 7560, dtype: object\n",
      "0        500.0\n",
      "1       1500.0\n",
      "2        330.0\n",
      "3        500.0\n",
      "4        330.0\n",
      "         ...  \n",
      "7555       NaN\n",
      "7556       NaN\n",
      "7557       NaN\n",
      "7558       NaN\n",
      "7559       NaN\n",
      "Name: capacity, Length: 7560, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Identify the problematic value in the 'capacity' column\n",
    "print(df['capacity'])\n",
    "\n",
    "# Removing and replacing the values in column with diff. measuring unit to just ml and removing ml symbol\n",
    "df['capacity'] = df['capacity'].replace('500ml', 500)\n",
    "df['capacity'] = df['capacity'].replace('1.5lt', 1500)\n",
    "df['capacity'] = df['capacity'].replace('330ml', 330)\n",
    "\n",
    "# Convert the 'capacity' column to float\n",
    "df['capacity'] = pd.to_numeric(df['capacity'], errors='coerce')\n",
    "\n",
    "# Verify the conversion\n",
    "print(df['capacity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id      date    city       lat      long       pop    shop  \\\n",
      "0     0.0  31/01/12  Athens  37.97945  23.71622  672130.0  shop_1   \n",
      "1     1.0  31/01/12  Athens  37.97945  23.71622  672130.0  shop_1   \n",
      "2     2.0  31/01/12  Athens  37.97945  23.71622  672130.0  shop_1   \n",
      "3     3.0  31/01/12  Athens  37.97945  23.71622  672130.0  shop_1   \n",
      "4     4.0  31/01/12  Athens  37.97945  23.71622  672130.0  shop_1   \n",
      "...   ...       ...     ...       ...       ...       ...     ...   \n",
      "7555  NaN       NaN     NaN       NaN       NaN       NaN     NaN   \n",
      "7556  NaN       NaN     NaN       NaN       NaN       NaN     NaN   \n",
      "7557  NaN       NaN     NaN       NaN       NaN       NaN     NaN   \n",
      "7558  NaN       NaN     NaN       NaN       NaN       NaN     NaN   \n",
      "7559  NaN       NaN     NaN       NaN       NaN       NaN     NaN   \n",
      "\n",
      "            brand container  capacity  price  quantity  \n",
      "0     kinder-cola     glass     500.0   0.96   13280.0  \n",
      "1     kinder-cola   plastic    1500.0   2.86    6727.0  \n",
      "2     kinder-cola       can     330.0   0.87    9848.0  \n",
      "3      adult-cola     glass     500.0   1.00   20050.0  \n",
      "4      adult-cola       can     330.0   0.39   25696.0  \n",
      "...           ...       ...       ...    ...       ...  \n",
      "7555          NaN       NaN     500.0    NaN       NaN  \n",
      "7556          NaN       NaN     500.0    NaN       NaN  \n",
      "7557          NaN       NaN     500.0    NaN       NaN  \n",
      "7558          NaN       NaN     500.0    NaN       NaN  \n",
      "7559          NaN       NaN     500.0    NaN       NaN  \n",
      "\n",
      "[7560 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#replacing null values in capacity column with median of that column\n",
    "median_values = df['capacity'].median()\n",
    "\n",
    "# Replace NaN values with median\n",
    "df['capacity'].fillna(median_values, inplace=True)\n",
    "\n",
    "# Verify that NaN values are replaced\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6391 entries, 0 to 6479\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         6391 non-null   float64\n",
      " 1   date       6391 non-null   object \n",
      " 2   city       6391 non-null   object \n",
      " 3   lat        6391 non-null   float64\n",
      " 4   long       6391 non-null   float64\n",
      " 5   pop        6391 non-null   float64\n",
      " 6   shop       6391 non-null   object \n",
      " 7   brand      6391 non-null   object \n",
      " 8   container  6391 non-null   object \n",
      " 9   capacity   6391 non-null   float64\n",
      " 10  price      6391 non-null   float64\n",
      " 11  quantity   6391 non-null   float64\n",
      "dtypes: float64(7), object(5)\n",
      "memory usage: 649.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# removing all the remaining rows with null values as it was throwing errors\n",
    "# Identify columns with NaN values\n",
    "columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Print columns with NaN values\n",
    "print(\"Columns with NaN values:\", columns_with_nan)\n",
    "\n",
    "# Remove rows with NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Verify that NaN values are removed\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean Squared Error: 253605610.09772924\n",
      "Decision Tree Mean Squared Error: 299417990.9122438\n",
      "XGB Mean Squared Error: 253710753.28492486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to train and evaluate a model using GroupedTimeSeriesSplit\n",
    "def train_and_evaluate_model(data, features, target, model_type='random_forest', n_splits=5, group_column=None):\n",
    "    # Initialize the model\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "    elif model_type == 'decision_tree':\n",
    "        model = DecisionTreeRegressor(random_state=42)\n",
    "    elif model_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model_type. Choose either 'random_forest' or 'decision_tree'.\")\n",
    "    \n",
    "    # Initialize the custom cross-validator\n",
    "    gkf = GroupedTimeSeriesSplit(n_splits=n_splits, group_column=group_column)\n",
    "    \n",
    "    # Initialize lists to store evaluation metrics\n",
    "    mse_scores = []\n",
    "    \n",
    "    # Iterate over the splits\n",
    "    for train_index, test_index in gkf.split(data):\n",
    "        # Split data into train and test sets\n",
    "        train_data, test_data = data.iloc[train_index], data.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_data[features], train_data[target])\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(test_data[features])\n",
    "        \n",
    "        # Calculate Mean Squared Error\n",
    "        mse = mean_squared_error(test_data[target], predictions)\n",
    "        \n",
    "        # Store the MSE\n",
    "        mse_scores.append(mse)\n",
    "    \n",
    "    # Calculate the mean of MSE scores\n",
    "    mean_mse = np.mean(mse_scores)\n",
    "    \n",
    "    return mean_mse\n",
    "\n",
    "# Features and target variable\n",
    "features = [\"pop\", \"capacity\", \"price\"]\n",
    "target = \"quantity\"\n",
    "\n",
    "# Evaluate the RandomForestRegressor model\n",
    "rf_mse = train_and_evaluate_model(df, features, target, model_type='random_forest', n_splits=4, group_column=\"city\")\n",
    "print(\"Random Forest Mean Squared Error:\", rf_mse)\n",
    "\n",
    "# Evaluate the DecisionTreeRegressor model\n",
    "dt_xgb = train_and_evaluate_model(df, features, target, model_type='decision_tree', n_splits=4, group_column=\"city\")\n",
    "print(\"Decision Tree Mean Squared Error:\", dt_xgb)\n",
    "\n",
    "# Evaluate the XGB model\n",
    "dt_mse = train_and_evaluate_model(df, features, target, model_type='xgb', n_splits=4, group_column=\"city\")\n",
    "print(\"XGB Mean Squared Error:\", dt_mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
